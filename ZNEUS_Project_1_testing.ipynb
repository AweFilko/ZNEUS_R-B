{
 "cells": [
  {
   "cellId": "eaba7f364f974a6caad7e3b07a2f0ac9",
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "eaba7f364f974a6caad7e3b07a2f0ac9",
    "deepnote_cell_type": "text-cell-h1"
   },
   "source": "# Imports and data fetching",
   "block_group": "ad9918f3a99b43f5a29336dac216c6f9"
  },
  {
   "cellId": "49d7682549ff49ecb51dddb1fe9771a4",
   "cell_type": "code",
   "metadata": {
    "source_hash": "27f3d23a",
    "execution_start": 1762381083946,
    "execution_millis": 6210,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "49d7682549ff49ecb51dddb1fe9771a4",
    "deepnote_cell_type": "code"
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_score\n",
    "import itertools\n"
   ],
   "block_group": "d11137b78ad74ce4a973df0994228238",
   "outputs_reference": "dbtable:cell_outputs/d96e4b5d-4fc2-4ef5-984c-42d21e8afd11",
   "content_dependencies": {
    "usedVariables": [],
    "importedModules": [
     "pd",
     "plt",
     "sns",
     "stats",
     "np"
    ],
    "definedVariables": []
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "240a56c9550f47748b84b029bffcd08b",
   "cell_type": "code",
   "metadata": {
    "source_hash": "509cbf29",
    "execution_start": 1762381090206,
    "execution_millis": 1406,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "240a56c9550f47748b84b029bffcd08b",
    "deepnote_cell_type": "code"
   },
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "magic_gamma_telescope = fetch_ucirepo(id=159)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "DS_feature = magic_gamma_telescope.data.features\n",
    "DS_target = magic_gamma_telescope.data.targets\n",
    "\n",
    "# metadata\n",
    "print(magic_gamma_telescope.metadata)\n",
    "\n",
    "# variable information\n",
    "print(magic_gamma_telescope.variables)\n",
    "\n"
   ],
   "block_group": "8d60baf9d8994093946b9a1f67ce5d25",
   "outputs_reference": "s3:deepnote-cell-outputs-production/17a8703f-25d9-49bb-b376-8ed11c2f6a32",
   "content_dependencies": {
    "usedVariables": [
     "fetch_ucirepo",
     "magic_gamma_telescope"
    ],
    "importedModules": [
     "fetch_ucirepo"
    ],
    "definedVariables": [
     "DS_feature",
     "DS_target",
     "magic_gamma_telescope"
    ]
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "edc028fb2e9343dfa23ef0089d6605c5",
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "edc028fb2e9343dfa23ef0089d6605c5",
    "deepnote_cell_type": "text-cell-h3"
   },
   "source": "### yay",
   "block_group": "7cd7c8f2de17414c82f596a05f63ca78"
  },
  {
   "cellId": "0277510ca06141b2b4852697a2cd6729",
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "0277510ca06141b2b4852697a2cd6729",
    "deepnote_cell_type": "text-cell-p"
   },
   "source": "",
   "block_group": "07a47b92d25b4d87aa12c06b0e459765"
  },
  {
   "cellId": "032c6501bef04f7a970a6b02aab9135a",
   "cell_type": "code",
   "metadata": {
    "source_hash": "a843147c",
    "execution_start": 1762381091677,
    "execution_millis": 0,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "032c6501bef04f7a970a6b02aab9135a",
    "deepnote_cell_type": "code"
   },
   "source": "#data exloration\nprint(DS_feature.describe())\n\nprint(\"-------------------------------------------------------------\")\n\nprint(DS_target.describe())\n",
   "block_group": "50df33a33a6a4b709a19f754fd7e9e3f",
   "outputs_reference": "s3:deepnote-cell-outputs-production/c0795316-b0ff-4c6a-8422-e4fc7cb39c01",
   "content_dependencies": {
    "usedVariables": [
     "DS_feature",
     "DS_target"
    ],
    "importedModules": [],
    "definedVariables": []
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "1450c923b8c0432c8b9a9fc5449b7275",
   "cell_type": "code",
   "metadata": {
    "source_hash": "a1b4e5bf",
    "execution_start": 1762381091742,
    "execution_millis": 4,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "1450c923b8c0432c8b9a9fc5449b7275",
    "deepnote_cell_type": "code"
   },
   "source": "print(\"Duplicates in features:\", DS_feature.duplicated().sum())\n\n#DS_feature = DS_feature.drop_duplicates()\n",
   "block_group": "236e169b6a2a435ca161ef484fe653c5",
   "outputs_reference": "dbtable:cell_outputs/5b0b5069-d939-4d51-a944-27f2e0646afd",
   "content_dependencies": {
    "usedVariables": [
     "DS_feature"
    ],
    "importedModules": [],
    "definedVariables": []
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "a037faf503c1491abadb39555e653c78",
   "cell_type": "code",
   "metadata": {
    "source_hash": "19725dbe",
    "execution_start": 1762381091796,
    "execution_millis": 1,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "a037faf503c1491abadb39555e653c78",
    "deepnote_cell_type": "code"
   },
   "source": "#anomalies detected\ndef count_anomalies(df, column, normal_min, normal_max):\n    mask_normal = (df[column] >= normal_min) & (df[column] <= normal_max)\n    anomalies = (~mask_normal).sum()\n    return anomalies\n\nprint(f\"fLength: \", count_anomalies(DS_feature, 'fLength', 0, 1000))\nprint(f\"fWidth: \", count_anomalies(DS_feature, 'fWidth', 0, 1000))\nprint(f\"fSize: \", count_anomalies(DS_feature, 'fSize', 0, 1000))\nprint(f\"fAlpha: \", count_anomalies(DS_feature, 'fAlpha', 0, 180))\nprint(f\"fDist: \", count_anomalies(DS_feature, 'fDist', 0, 1000))\n",
   "block_group": "fea0a2be4c0d4ccab5ea2f81d6adc9ed",
   "outputs_reference": "dbtable:cell_outputs/a76a98f9-5f20-4db9-865f-a2405e414cdd",
   "content_dependencies": {
    "usedVariables": [
     "DS_feature",
     "count_anomalies",
     "df"
    ],
    "importedModules": [],
    "definedVariables": [
     "count_anomalies",
     "rules"
    ]
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "6419c31c18a24c20876caae40a13a603",
   "cell_type": "code",
   "metadata": {
    "source_hash": "31642093",
    "execution_start": 1762381091858,
    "execution_millis": 16,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "6419c31c18a24c20876caae40a13a603",
    "deepnote_cell_type": "code"
   },
   "source": [
    "features = ['fLength', 'fWidth', 'fSize', 'fConc', 'fConc1', 'fAsym', 'fM3Long', 'fM3Trans', 'fAlpha', 'fDist']\n",
    "\n",
    "\n",
    "for col in features:\n",
    "    Q1 = DS_feature[col].quantile(0.25)\n",
    "    Q3 = DS_feature[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "\n",
    "    # set outliers to NaN\n",
    "\n",
    "    DS_feature[col] = DS_feature[col].where(DS_feature[col].between(lower, upper), np.nan)\n",
    "    #DS_feature.loc[(DS_feature[col] < lower) | (DS_feature[col] > upper), col] = np.nan\n",
    "\n",
    "\n",
    "# --- Missingness and outlriers handling ---\n",
    "threshold = 30\n",
    "\n",
    "missing_pct = DS_feature.isna().mean() * 100\n",
    "to_drop_cols = missing_pct[missing_pct > threshold ].index.tolist()\n",
    "to_impute_cols = missing_pct[(missing_pct >= 0.1) & (missing_pct <= threshold)].index.tolist()\n",
    "\n",
    "print(f'Missing percentages:\\n{missing_pct}')\n",
    "print(f'Number of outliers: {(DS_feature.isna().sum().sum())}')\n",
    "\n",
    "dropped_cols = []\n",
    "imputed_cols = []\n",
    "\n",
    "# drop columns with more than 30% (threshold) missing values\n",
    "for col in to_drop_cols:\n",
    "    if col in DS_feature.columns:\n",
    "        DS_feature = DS_feature.drop(columns=[col])\n",
    "        dropped_cols.append(col)\n",
    "\n",
    "# for columns with 0.1-30% missing -> impute\n",
    "\n",
    "for col in to_impute_cols:\n",
    "    if col not in DS_feature.columns:\n",
    "        continue\n",
    "    # checks if the column’s dtype is numeric\n",
    "    if pd.api.types.is_numeric_dtype(DS_feature[col]):\n",
    "        median_val = DS_feature[col].median(skipna=True)\n",
    "        # replaces missing values with the median (less sensetive to outliners than mean)\n",
    "        # inplace=True means the changes are applied directly to the DataFrame\n",
    "        DS_feature[col].fillna(median_val, inplace=True)\n",
    "        imputed_cols.append((col, \"median\", median_val))\n",
    "    else:\n",
    "        # for non-numeric, impute with mode if available\n",
    "        try:\n",
    "            mode_val = DS_feature[col].mode(dropna=True)\n",
    "            if len(mode_val) > 0:\n",
    "                mode_val = mode_val.iloc[0]\n",
    "                DS_feature[col].fillna(mode_val, inplace=True)\n",
    "                imputed_cols.append((col, \"mode\", mode_val))\n",
    "            else:\n",
    "                # if no mode, fill with placeholder\n",
    "                DS_feature[col].fillna(\"missing\", inplace=True)\n",
    "                imputed_cols.append((col, \"placeholder\", \"missing\"))\n",
    "        except Exception as e:\n",
    "            DS_feature[col].fillna(\"missing\", inplace=True)\n",
    "            imputed_cols.append((col, \"placeholder\", \"missing\"))"
   ],
   "block_group": "703aad8b72a84500b35b541f06539c6b",
   "outputs_reference": "s3:deepnote-cell-outputs-production/a094afc9-6aa4-4d06-b8fb-7206368c97f5",
   "content_dependencies": {
    "usedVariables": [
     "DS_feature",
     "Exception",
     "IQR",
     "Q1",
     "Q3",
     "col",
     "dropped_cols",
     "features",
     "imputed_cols",
     "lower",
     "median_val",
     "missing_pct",
     "mode_val",
     "np",
     "pd",
     "threshold",
     "to_drop_cols",
     "to_impute_cols",
     "upper"
    ],
    "importedModules": [],
    "definedVariables": [
     "DS_feature",
     "IQR",
     "Q1",
     "Q3",
     "col",
     "dropped_cols",
     "features",
     "imputed_cols",
     "lower",
     "median_val",
     "missing_pct",
     "mode_val",
     "threshold",
     "to_drop_cols",
     "to_impute_cols",
     "upper"
    ]
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "28843e64347243e3982e94109d10a4e2",
   "cell_type": "code",
   "metadata": {
    "source_hash": "2765ae3e",
    "execution_start": 1762381091936,
    "execution_millis": 2,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "28843e64347243e3982e94109d10a4e2",
    "deepnote_cell_type": "code"
   },
   "source": [
    "print(\"Missingness handling summary:\")\n",
    "print(f'Dropped columns (missingness > {threshold}%): {len(dropped_cols)}\\n{dropped_cols}')\n",
    "print(f'Imputed columns (missingness between 5% and {threshold}%): {len(imputed_cols)}\\n{imputed_cols}')"
   ],
   "block_group": "d0b50a808a3348e1ae284753fd19e5a1",
   "outputs_reference": "dbtable:cell_outputs/e4b2f141-c49b-42de-8a6c-aab7da4e7837",
   "content_dependencies": {
    "usedVariables": [
     "dropped_cols",
     "imputed_cols",
     "threshold"
    ],
    "importedModules": [],
    "definedVariables": []
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "23c7852c40254b448d36130d3ae1aece",
   "cell_type": "code",
   "metadata": {
    "source_hash": "67160c10",
    "execution_start": 1762381092007,
    "execution_millis": 1693,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "23c7852c40254b448d36130d3ae1aece",
    "deepnote_cell_type": "code"
   },
   "source": [
    "features = ['fLength', 'fWidth', 'fSize', 'fConc', 'fConc1', 'fAsym', 'fM3Long', 'fM3Trans', 'fAlpha', 'fDist']\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15,8))\n",
    "\n",
    "for ax, feature in zip(axes.flatten(), features):\n",
    "    stats.probplot(DS_feature[feature], dist=\"norm\", plot=ax)\n",
    "    ax.set_title(f\"QQ Plot: {feature}\", fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "block_group": "6a4e34190c22441dac3cb579d9e749fe",
   "outputs_reference": "s3:deepnote-cell-outputs-production/aafd01e3-fb52-4ea2-aef5-45c2fe9d9244",
   "content_dependencies": {
    "usedVariables": [
     "DS_feature",
     "ax",
     "axes",
     "feature",
     "features",
     "plt",
     "stats"
    ],
    "importedModules": [],
    "definedVariables": [
     "ax",
     "axes",
     "feature",
     "features",
     "fig"
    ]
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "4a8937268b014aeb82b9b5ed434aa0ec",
   "cell_type": "code",
   "metadata": {
    "source_hash": "7e72cc4c",
    "execution_start": 1762381093756,
    "execution_millis": 1019,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "4a8937268b014aeb82b9b5ed434aa0ec",
    "deepnote_cell_type": "code"
   },
   "source": [
    "DS_feature.plot(kind='box', subplots=True,\n",
    "                              layout=(2, 5), figsize=(15, 10), sharex=False)\n",
    "plt.suptitle(\"Boxplots for all features\")\n",
    "plt.show()"
   ],
   "block_group": "6d28656290774ad98972a4f61add59ec",
   "outputs_reference": "s3:deepnote-cell-outputs-production/596db1ac-8324-4b9b-a02b-d6fec3957d6a",
   "content_dependencies": {
    "usedVariables": [
     "DS_feature",
     "plt"
    ],
    "importedModules": [],
    "definedVariables": []
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "f78d696e95534fb2a4bda696ec7e1bef",
   "cell_type": "code",
   "metadata": {
    "source_hash": "84bede73",
    "execution_start": 1762381094827,
    "execution_millis": 4138,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "f78d696e95534fb2a4bda696ec7e1bef",
    "deepnote_cell_type": "code"
   },
   "source": [
    "features = ['fLength', 'fWidth', 'fSize', 'fConc', 'fConc1', 'fAsym', 'fM3Long', 'fM3Trans', 'fAlpha', 'fDist']\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15,8))\n",
    "\n",
    "for ax, feature in zip(axes.flatten(), features):\n",
    "    sns.histplot(DS_feature[feature], kde=True, ax=ax)\n",
    "    ax.set_title(f\"Distribution of {feature} by class\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "block_group": "ba512404419b4a0e890ff77a0a3f399a",
   "outputs_reference": "s3:deepnote-cell-outputs-production/3e5c343f-14f5-4a32-9058-72d5b41ec4f4",
   "content_dependencies": {
    "usedVariables": [
     "DS_feature",
     "ax",
     "axes",
     "feature",
     "features",
     "plt",
     "sns"
    ],
    "importedModules": [],
    "definedVariables": [
     "ax",
     "axes",
     "feature",
     "features",
     "fig"
    ]
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "0a84c2b3fe4042b9b2b95ca830786964",
   "cell_type": "code",
   "metadata": {
    "source_hash": "7e39798",
    "execution_start": 1762381099027,
    "execution_millis": 0,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "0a84c2b3fe4042b9b2b95ca830786964",
    "deepnote_cell_type": "code"
   },
   "source": "print(DS_feature.shape)\n",
   "block_group": "b1d4f55543224fc284c85b825ec7a129",
   "outputs_reference": "dbtable:cell_outputs/ef7166f0-8769-4149-9e29-754884648014",
   "content_dependencies": {
    "usedVariables": [
     "DS_feature"
    ],
    "importedModules": [],
    "definedVariables": []
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "a639e13b1c03444aa791a935314a580c",
   "cell_type": "code",
   "metadata": {
    "source_hash": "bfd4f834",
    "execution_start": 1762381099086,
    "execution_millis": 209,
    "deepnote_table_state": {
     "sortBy": [],
     "filters": [],
     "pageSize": 100,
     "pageIndex": 0,
     "columnOrder": [
      "class"
     ],
     "hiddenColumnIds": [],
     "columnDisplayNames": [],
     "conditionalFilters": [],
     "cellFormattingRules": [],
     "wrappedTextColumnIds": []
    },
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "deepnote_table_loading": false,
    "cell_id": "a639e13b1c03444aa791a935314a580c",
    "deepnote_cell_type": "code"
   },
   "source": "\nif DS_target['class'].dtype == 'object':\n    DS_target['class'] = DS_target['class'].map({'g': 1, 'h': 0})\n\nplt.figure(figsize=(15, 8))\nsns.countplot(x='class', data=DS_target, palette='Set2', hue='class')\nplt.title(\"Distribution of Classes (Gamma vs Hadron)\")\nplt.xlabel(\"Class\")\nplt.ylabel(\"Count\")\nplt.tight_layout()\nplt.show()\n\n#DS_target['class'].value_counts()",
   "block_group": "a3f0fe5565ae41719b75a6604c449d4a",
   "outputs_reference": "s3:deepnote-cell-outputs-production/8296d7c2-af8c-4c3a-8ee7-9d30a8b20983",
   "content_dependencies": {
    "usedVariables": [
     "DS_target",
     "plt",
     "sns"
    ],
    "importedModules": [],
    "definedVariables": []
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "7df7c403d8aa409db525f3685a2a99a1",
   "cell_type": "code",
   "metadata": {
    "source_hash": "e26a7281",
    "execution_start": 1762381099346,
    "execution_millis": 458,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "7df7c403d8aa409db525f3685a2a99a1",
    "deepnote_cell_type": "code"
   },
   "source": "df = DS_feature.copy()\ndf['class'] = DS_target\n\ndf.drop_duplicates()\n\nif df['class'].dtype == 'object':\n    df['class'] = df['class'].map({'g': 1, 'h': 0})\n\ncorr_matrix = df.corr(numeric_only=True)\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\nplt.title(\"Correlation Matrix - MAGIC Gamma Telescope Dataset\", fontsize=14)\nplt.tight_layout()\nplt.show()",
   "block_group": "a381ec88b4b54ec8888e76457ea8dd8b",
   "outputs_reference": "s3:deepnote-cell-outputs-production/4e2b6175-b941-4932-8355-8003de8f676e",
   "content_dependencies": {
    "usedVariables": [
     "DS_feature",
     "DS_target",
     "corr_matrix",
     "df",
     "plt",
     "sns"
    ],
    "importedModules": [],
    "definedVariables": [
     "corr_matrix",
     "df"
    ]
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "5eebc1860c3a4bad857a320a3240caa0",
   "cell_type": "code",
   "metadata": {
    "source_hash": "72c65255",
    "execution_start": 1762381099867,
    "execution_millis": 116,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "5eebc1860c3a4bad857a320a3240caa0",
    "deepnote_cell_type": "code"
   },
   "source": "from sklearn.preprocessing import PowerTransformer\nfrom sklearn.impute import SimpleImputer\n\nDS_feature_scaled = DS_feature.copy()\n\nimputer = SimpleImputer(strategy='median')\nDS_feature = pd.DataFrame(imputer.fit_transform(DS_feature), columns=DS_feature.columns)\n\ncols_power  = ['fLength', 'fWidth', 'fSize', 'fAlpha','fAsym', 'fM3Long', 'fM3Trans']\n\npt = PowerTransformer(method='yeo-johnson')\n\nDS_feature_scaled[cols_power] = pt.fit_transform(DS_feature[cols_power])",
   "block_group": "7950ea244f534c24978564ec9fafeb4b",
   "outputs_reference": null,
   "content_dependencies": {
    "usedVariables": [
     "DS_feature",
     "DS_feature_scaled",
     "PowerTransformer",
     "SimpleImputer",
     "cols_power",
     "imputer",
     "pd",
     "pt"
    ],
    "importedModules": [
     "PowerTransformer",
     "SimpleImputer"
    ],
    "definedVariables": [
     "DS_feature",
     "DS_feature_scaled",
     "cols_power",
     "imputer",
     "pt"
    ]
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "10fbbd52c47c496f8aea514288ebf290",
   "cell_type": "code",
   "metadata": {
    "source_hash": "e34339c0",
    "execution_start": 1762381100038,
    "execution_millis": 4230,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "10fbbd52c47c496f8aea514288ebf290",
    "deepnote_cell_type": "code"
   },
   "source": "features = ['fLength', 'fWidth', 'fSize', 'fConc', 'fConc1', 'fAsym', 'fM3Long', 'fM3Trans', 'fAlpha', 'fDist']\n\nfig, axes = plt.subplots(2, 5, figsize=(15,8))\n\nfor ax, feature in zip(axes.flatten(), features):\n    sns.histplot(DS_feature_scaled[feature], kde=True, ax=ax)\n    ax.set_title(f\"Distribution of {feature} by class\")\n\n\nplt.tight_layout()\nplt.show()",
   "block_group": "8fabb9b14da145eaaf54db896b0cb1ba",
   "outputs_reference": "s3:deepnote-cell-outputs-production/f9fa5dfc-3759-406f-acb7-663218c62406",
   "content_dependencies": {
    "usedVariables": [
     "DS_feature_scaled",
     "ax",
     "axes",
     "feature",
     "features",
     "plt",
     "sns"
    ],
    "importedModules": [],
    "definedVariables": [
     "ax",
     "axes",
     "feature",
     "features",
     "fig"
    ]
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "e147246e38dc430787f8d9f43d9292c3",
   "cell_type": "code",
   "metadata": {
    "source_hash": "99f58093",
    "execution_start": 1762381104346,
    "execution_millis": 1314,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "e147246e38dc430787f8d9f43d9292c3",
    "deepnote_cell_type": "code"
   },
   "source": "features = ['fLength', 'fWidth', 'fSize', 'fConc', 'fConc1', 'fAsym', 'fM3Long', 'fM3Trans', 'fAlpha', 'fDist']\n\nfig, axes = plt.subplots(2, 5, figsize=(15,8))\n\nfor ax, feature in zip(axes.flatten(), features):\n    stats.probplot(DS_feature_scaled[feature], dist=\"norm\", plot=ax)\n    ax.set_title(f\"QQ Plot: {feature}\", fontsize=8)\n\nplt.tight_layout()\nplt.show()",
   "block_group": "bc846af3e6644dc290deb6b6d207da65",
   "outputs_reference": "s3:deepnote-cell-outputs-production/3c3de7a3-e843-45ec-8f1b-fa97b34e25ee",
   "content_dependencies": {
    "usedVariables": [
     "DS_feature_scaled",
     "ax",
     "axes",
     "feature",
     "features",
     "plt",
     "stats"
    ],
    "importedModules": [],
    "definedVariables": [
     "ax",
     "axes",
     "feature",
     "features",
     "fig"
    ]
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "83607ae5bca246e39b7b67b035b7d14c",
   "cell_type": "code",
   "metadata": {
    "source_hash": "cbf65db7",
    "execution_start": 1762381105706,
    "execution_millis": 1,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "83607ae5bca246e39b7b67b035b7d14c",
    "deepnote_cell_type": "code"
   },
   "source": "from sklearn.model_selection import train_test_split\n\nX = DS_feature_scaled\ny = DS_target[\"class\"]\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y \n)",
   "block_group": "d4d829f416754aabb4e5d333e92daab4",
   "outputs_reference": null,
   "content_dependencies": {
    "usedVariables": [
     "DS_feature_scaled",
     "DS_target",
     "X",
     "train_test_split",
     "y"
    ],
    "importedModules": [
     "train_test_split"
    ],
    "definedVariables": [
     "X",
     "X_test",
     "X_train",
     "y",
     "y_test",
     "y_train"
    ]
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "d48002a8aa224eb6abaff18ba778c424",
   "cell_type": "code",
   "metadata": {
    "source_hash": "2d6eae5d",
    "execution_start": 1762381105756,
    "execution_millis": 2168,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "d48002a8aa224eb6abaff18ba778c424",
    "deepnote_cell_type": "code"
   },
   "source": "from sklearn.linear_model import LinearRegression\n\nremaining_feat = list(features)\nselected_feat = []\ncurrent_score = 0.0\nbest_new_score = 0.0\n\nprogress = []\n\nwhile remaining_feat:\n    score_with_candidates = []\n\n    for candidate in remaining_feat:\n        model = LinearRegression()\n        model.fit(X_train[selected_feat + [candidate]], y_train)\n        score = model.score(X_test[selected_feat + [candidate]], y_test)\n        score_with_candidates.append((score, candidate))\n\n    score_with_candidates.sort()\n    best_new_score, best_candidate = score_with_candidates.pop()\n\n    if current_score < best_new_score:\n        remaining_feat.remove(best_candidate)\n        selected_feat.append(best_candidate)\n        current_score = best_new_score\n        # print(f\"Adding {best_candidate} with score {current_score}\")\n\n        progress.append((len(selected_feat), best_candidate, current_score))\n\n    else:\n        break\n\nprint(f\"Forward Selection Result: {selected_feat};\")\nprint(f\"Number of Selected Features: {len(selected_feat)};\")\nprint(f\"Final Validation Score: {current_score:.4f}\")\n",
   "block_group": "9094ec4a9a7c49b58cf552ec87e8daa9",
   "outputs_reference": "dbtable:cell_outputs/2a7ce261-fac2-478f-9378-a6f85a969092",
   "content_dependencies": {
    "usedVariables": [
     "LinearRegression",
     "X_test",
     "X_train",
     "best_candidate",
     "best_new_score",
     "candidate",
     "current_score",
     "features",
     "model",
     "progress",
     "remaining_feat",
     "score",
     "score_with_candidates",
     "selected_feat",
     "y_test",
     "y_train"
    ],
    "importedModules": [
     "LinearRegression"
    ],
    "definedVariables": [
     "best_candidate",
     "best_new_score",
     "candidate",
     "current_score",
     "model",
     "progress",
     "remaining_feat",
     "score",
     "score_with_candidates",
     "selected_feat"
    ]
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "2694f92301e9467391a65b9bbb32ca1d",
   "cell_type": "code",
   "metadata": {
    "source_hash": "24fd5769",
    "execution_start": 1762381107976,
    "execution_millis": 124,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "2694f92301e9467391a65b9bbb32ca1d",
    "deepnote_cell_type": "code"
   },
   "source": "steps, feats, scores = zip(*progress)\nplt.figure(figsize=(8,4))\nplt.plot(steps, scores, marker='o')\nplt.title(\"Forward Selection Performance\")\nplt.xlabel(\"Number of Selected Features\")\nplt.ylabel(\"Validation R²\")\nplt.grid(True)\nplt.show()",
   "block_group": "bc29ac9f321f4186b42ae008acaf27f2",
   "outputs_reference": "s3:deepnote-cell-outputs-production/56cddab5-baae-49c2-82dc-5905a7c2150c",
   "content_dependencies": {
    "usedVariables": [
     "plt",
     "progress",
     "scores",
     "steps"
    ],
    "importedModules": [],
    "definedVariables": [
     "feats",
     "scores",
     "steps"
    ]
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "6cc13ae0486f4f8d8d33b05966837903",
   "cell_type": "code",
   "metadata": {
    "source_hash": "42c22ea8",
    "execution_start": 1762381108156,
    "execution_millis": 1,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "6cc13ae0486f4f8d8d33b05966837903",
    "deepnote_cell_type": "code"
   },
   "source": "remaining_feat = list(X_train.columns)\ncurrent_score = 0.0\n\nmodel = LinearRegression()\nmodel.fit(X_train[remaining_feat], y_train)\nbest_score = model.score(X_test[remaining_feat], y_test)\n\nscores_progress = [(len(remaining_feat), best_score)]\nprint(f\"Initial R² with all features: {best_score:.4f}\")",
   "block_group": "48d2aa6acf1340269ee1ae0649899084",
   "outputs_reference": "dbtable:cell_outputs/050e2a38-42f1-4e63-984d-0806018abf69",
   "content_dependencies": {
    "usedVariables": [
     "LinearRegression",
     "X_test",
     "X_train",
     "best_score",
     "model",
     "remaining_feat",
     "y_test",
     "y_train"
    ],
    "importedModules": [],
    "definedVariables": [
     "best_score",
     "current_score",
     "model",
     "remaining_feat",
     "scores_progress"
    ]
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "0fce5a14702d4ee7892cb8975ff794d8",
   "cell_type": "code",
   "metadata": {
    "source_hash": "f9b9a367",
    "execution_start": 1762381108266,
    "execution_millis": 2257,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "0fce5a14702d4ee7892cb8975ff794d8",
    "deepnote_cell_type": "code"
   },
   "source": "while len(remaining_feat) > 1:\n    scores_with_candidates = []\n    \n    for feature in remaining_feat:\n        reduced_features = [f for f in remaining_feat if f != feature]\n        model = LinearRegression()\n        model.fit(X_train[reduced_features], y_train)\n        score = model.score(X_test[reduced_features], y_test)\n        scores_with_candidates.append((score, feature))\n    \n    scores_with_candidates.sort(reverse=True)\n    best_new_score, worst_feature = scores_with_candidates[0]\n\n    if best_new_score < best_score - 0.001:\n        break\n\n    remaining_feat.remove(worst_feature)\n    best_score = max(best_new_score, best_score)\n    scores_progress.append((len(remaining_feat), best_new_score))\n    print(f\"Removed {worst_feature}, new R²: {best_new_score:.4f}\")\n\nprint(\"Backward Elimination Result:\")\nprint(f\"Selected features: {remaining_feat};\")\nprint(f\"Number of selected features: {len(remaining_feat)}\")\nprint(f\"Final Validation R²: {best_score:.4f}\")",
   "block_group": "3073d68d194a42e3945e29b6ac3c99b5",
   "outputs_reference": "dbtable:cell_outputs/fdee8178-cc0e-4ce7-966f-33b95a621aa1",
   "content_dependencies": {
    "usedVariables": [
     "LinearRegression",
     "X_test",
     "X_train",
     "best_new_score",
     "best_score",
     "f",
     "feature",
     "model",
     "reduced_features",
     "remaining_feat",
     "score",
     "scores_progress",
     "scores_with_candidates",
     "worst_feature",
     "y_test",
     "y_train"
    ],
    "importedModules": [],
    "definedVariables": [
     "best_new_score",
     "best_score",
     "f",
     "feature",
     "model",
     "reduced_features",
     "score",
     "scores_with_candidates",
     "worst_feature"
    ]
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "4a62f02e2aa44309a31e7d182a429521",
   "cell_type": "code",
   "metadata": {
    "source_hash": "1d520ba3",
    "execution_start": 1762381110586,
    "execution_millis": 86,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "4a62f02e2aa44309a31e7d182a429521",
    "deepnote_cell_type": "code"
   },
   "source": "steps, scores = zip(*scores_progress)\nplt.figure(figsize=(8,4))\nplt.plot(steps, scores, marker=\"o\", linestyle=\"-\", color=\"brown\")\nplt.title(\"Backward Elimination Performance\")\nplt.xlabel(\"Number of Remaining Features\")\nplt.ylabel(\"Validation R²\")\nplt.gca().invert_xaxis()\nplt.grid(True)\nplt.show()\n",
   "block_group": "c1594883bd5e4b77b206a20ea1a5980d",
   "outputs_reference": "s3:deepnote-cell-outputs-production/8536aebc-f484-4c21-9a4a-e4004c6f0cca",
   "content_dependencies": {
    "usedVariables": [
     "plt",
     "scores",
     "scores_progress",
     "steps"
    ],
    "importedModules": [],
    "definedVariables": [
     "scores",
     "steps"
    ]
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "6581e6b581604385a6b5cc98212e027c",
   "cell_type": "code",
   "metadata": {
    "source_hash": "2d5f30da",
    "execution_start": 1762381110717,
    "execution_millis": 0,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "6581e6b581604385a6b5cc98212e027c",
    "deepnote_cell_type": "code"
   },
   "source": [
    "test_split = 0.2\n",
    "batch_size = 256\n",
    "random_state = 14\n",
    "in_features = None\n",
    "learning_rate = 0.1\n",
    "epochs = 50\n",
    "dropout_rate = 0.0\n",
    "weight_decay = 1e-5\n"
   ],
   "block_group": "a3e6ad86a49142e1adb1035edacf6ecf",
   "outputs_reference": null,
   "content_dependencies": null,
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "d67493bdaa814522b53b9849542a131d",
   "cell_type": "code",
   "metadata": {
    "source_hash": "c53b20a6",
    "execution_start": 1762381110776,
    "execution_millis": 26,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "d67493bdaa814522b53b9849542a131d",
    "deepnote_cell_type": "code"
   },
   "source": [
    "T_features = DS_feature[['fLength', 'fWidth', 'fSize', 'fConc', 'fConc1', 'fAsym', 'fM3Long', 'fAlpha', 'fDist']].values\n",
    "T_labels = DS_target['class'].values\n",
    "\n",
    "in_features = T_features.shape[1]\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    T_features, T_labels, test_size=test_split, random_state=random_state\n",
    ")\n",
    "\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "val_ds = TensorDataset(X_val, y_val)\n"
   ],
   "block_group": "283b40b390b14eff9cf0e0e677458b5f",
   "outputs_reference": null,
   "content_dependencies": {
    "usedVariables": [
     "DS_feature"
    ],
    "importedModules": [],
    "definedVariables": [
     "DS_feature"
    ]
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "3691b28d82864d6194282901135b0add",
   "cell_type": "code",
   "metadata": {
    "source_hash": "de9b1c9e",
    "execution_start": 1762381110846,
    "execution_millis": 0,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "3691b28d82864d6194282901135b0add",
    "deepnote_cell_type": "code"
   },
   "source": "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)",
   "block_group": "63a262bdd46e4f2c8d5c472557d22bfb",
   "outputs_reference": null,
   "content_dependencies": null,
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "d4c42ec2528f4725a6334433d6ddb589",
   "cell_type": "code",
   "metadata": {
    "source_hash": "d40fea1c",
    "execution_start": 1762381110896,
    "execution_millis": 0,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "d4c42ec2528f4725a6334433d6ddb589",
    "deepnote_cell_type": "code"
   },
   "source": [
    "class MagicalNet(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim=64, dropout_p=dropout_rate):\n",
    "        super().__init__()\n",
    "        # Layer 1: Linear → BatchNorm → ReLU → Dropout\n",
    "        self.fc1 = nn.Linear(in_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.drop1 = nn.Dropout(dropout_p)\n",
    "\n",
    "        # Layer 2: Linear → BatchNorm → ReLU → Dropout\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.drop2 = nn.Dropout(dropout_p)\n",
    "\n",
    "        # Output layer\n",
    "        self.out = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Hidden layer 1\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.drop1(x)\n",
    "\n",
    "        # Hidden layer 2\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.drop2(x)\n",
    "\n",
    "        # Output (raw logits)\n",
    "        x = self.out(x)\n",
    "        return x"
   ],
   "block_group": "b6e2cb3ebee744fcaf934beaad9ddc8a",
   "outputs_reference": null,
   "content_dependencies": null,
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "ac625fe4eb874e1aa551242906a2b018",
   "cell_type": "code",
   "metadata": {
    "source_hash": "faff18f8",
    "execution_start": 1762381139309,
    "execution_millis": 1,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "ac625fe4eb874e1aa551242906a2b018",
    "deepnote_cell_type": "code"
   },
   "source": [
    "model = MagicalNet(in_dim=in_features, hidden_dim=64, dropout_p=dropout_rate)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([2.0]))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ],
   "block_group": "9c1fa6c985fe48e09abba44b59d37b60",
   "outputs_reference": null,
   "content_dependencies": null,
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "4d621f7e1f334750b17c19d37631f4de",
   "cell_type": "code",
   "metadata": {
    "source_hash": "407fcfdc",
    "execution_start": 1762381154776,
    "execution_millis": 5355,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "4d621f7e1f334750b17c19d37631f4de",
    "deepnote_cell_type": "code"
   },
   "source": "wandb.login()",
   "block_group": "fe4e85187e4445b09f06463f327b566f",
   "outputs_reference": "s3:deepnote-cell-outputs-production/58c825da-5208-4619-898f-a60d710ecb38",
   "content_dependencies": {
    "usedVariables": [
     "wandb"
    ],
    "importedModules": [
     "wandb"
    ],
    "definedVariables": []
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "08dedee5f05b4bacb4832ef7a8ac46bf",
   "cell_type": "code",
   "metadata": {
    "source_hash": "5069e8df",
    "execution_start": 1762381166170,
    "execution_millis": 6478,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "08dedee5f05b4bacb4832ef7a8ac46bf",
    "deepnote_cell_type": "code"
   },
   "source": "wandb.init(project=\"ZNEUS_R&B\", name=\"gamma_classification\",   \n    config={\n        \"epochs\": epochs,\n        \"batch_size\": batch_size,\n        \"learning_rate\": learning_rate,\n        \"architecture\": \"MagicalNet\"\n    })",
   "block_group": "789e7367ae324cd9b8873ea74d5bc018",
   "outputs_reference": "s3:deepnote-cell-outputs-production/193296c1-2039-448c-a56d-7ab47c626b37",
   "content_dependencies": {
    "usedVariables": [
     "wandb"
    ],
    "importedModules": [],
    "definedVariables": []
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "738e4cf5d0de40a19ba10d7aa96bb064",
   "cell_type": "code",
   "metadata": {
    "source_hash": "d5efa74a",
    "execution_start": 1762381328716,
    "execution_millis": 2833,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "738e4cf5d0de40a19ba10d7aa96bb064",
    "deepnote_cell_type": "code"
   },
   "source": [
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#\n",
    "#     for xb, yb in train_loader:\n",
    "#         xb, yb = xb, yb.unsqueeze(1)\n",
    "#         optimizer.zero_grad()\n",
    "#         logits = model(xb)\n",
    "#         loss = criterion(logits, yb)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item() * xb.size(0)\n",
    "#\n",
    "#     epoch_loss = running_loss / len(val_loader.dataset)\n",
    "#\n",
    "#     wandb.log({\"train_loss\": epoch_loss, \"epoch\": epoch + 1})\n",
    "#\n",
    "#     print(f\"Epoch {epoch+1}/{epochs} — loss: {epoch_loss:.4f}\")"
   ],
   "block_group": "fc44119665b646b3b7eabb6510fef796",
   "outputs_reference": "dbtable:cell_outputs/fd71ef38-c10b-4187-a86a-5652fc63e2a6",
   "content_dependencies": null,
   "outputs": [],
   "execution_count": null
  },
  {
   "cellId": "ff7060bbd4e14b0480c8b53b4526b6b9",
   "cell_type": "code",
   "metadata": {
    "source_hash": "c8330e5d",
    "execution_start": 1762381363907,
    "execution_millis": 0,
    "execution_context_id": "a36accf4-c15c-4590-81b2-dc9e829279fa",
    "cell_id": "ff7060bbd4e14b0480c8b53b4526b6b9",
    "deepnote_cell_type": "code"
   },
   "source": [
    "# model.eval()\n",
    "# all_preds = []\n",
    "# all_targets = []\n",
    "#\n",
    "# with torch.no_grad():\n",
    "#     for xb, yb in train_loader:\n",
    "#         logits = model(xb)\n",
    "#         probs = torch.sigmoid(logits)\n",
    "#         preds = (probs > 0.5).long()\n",
    "#         all_preds.append(preds.cpu())\n",
    "#         all_targets.append(yb.unsqueeze(1).long())\n",
    "#\n",
    "# all_preds = torch.cat(all_preds).squeeze().numpy()\n",
    "# all_targets = torch.cat(all_targets).squeeze().numpy()\n",
    "# accuracy = (all_preds == all_targets).mean()\n",
    "#\n",
    "# precision = precision_score(all_targets, all_preds)\n",
    "# recall = recall_score(all_targets, all_preds)\n",
    "# f1 = f1_score(all_targets, all_preds)\n",
    "# cm = confusion_matrix(all_targets, all_preds)\n",
    "#\n",
    "# print(f\"Accuracy: {accuracy:.4f}\")\n",
    "# print(f\"Precision: {precision:.4f}\")\n",
    "# print(f\"Recall: {recall:.4f}\")\n",
    "# print(f\"F1-score: {f1:.4f}\")\n",
    "# print(\"Confusion matrix:\\n\", cm)\n",
    "#\n",
    "# wandb.log({\n",
    "#     \"accuracy\": accuracy,\n",
    "#     \"precision\": precision,\n",
    "#     \"recall\": recall,\n",
    "#     \"f1_score\": f1\n",
    "# })\n"
   ],
   "block_group": "5b33d0675537478ebd3b49e5763943d6",
   "outputs_reference": "dbtable:cell_outputs/0c6fc38f-fac1-458a-a9c4-52836eee8882",
   "content_dependencies": null,
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "#\n",
    "# # --- Early stopping settings ---\n",
    "# monitor = \"f1\"           # which metric to monitor: \"f1\", \"precision\", \"recall\", or \"val_loss\"\n",
    "# mode = \"max\"             # \"max\" if higher is better, \"min\" if lower is better\n",
    "# patience = 100             # how many epochs to wait for improvement\n",
    "# best_metric = -float(\"inf\") if mode == \"max\" else float(\"inf\")\n",
    "# wait = 0\n",
    "#\n",
    "# best_model_path = \"best_model.pt\"\n",
    "#\n",
    "# for epoch in range(epochs):\n",
    "#\n",
    "#     # -------- training --------\n",
    "#\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     for xb, yb in train_loader:\n",
    "#         xb, yb = xb, yb.unsqueeze(1)            # keep shapes consistent\n",
    "#         optimizer.zero_grad()\n",
    "#         logits = model(xb)\n",
    "#         loss = criterion(logits, yb)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item() * xb.size(0)\n",
    "#\n",
    "#     train_epoch_loss = running_loss / len(train_loader.dataset)   # <- use train size\n",
    "#     wandb.log({\"train_loss\": train_epoch_loss, \"epoch\": epoch + 1})\n",
    "#\n",
    "#     # -------- validation / evaluation --------\n",
    "#\n",
    "#     model.eval()\n",
    "#     probs_list = []\n",
    "#     targets_list = []\n",
    "#     with torch.no_grad():\n",
    "#         for xb, yb in val_loader:               # validate on val_loader, not train_loader\n",
    "#             logits = model(xb)\n",
    "#             probs = torch.sigmoid(logits).cpu().numpy().squeeze()\n",
    "#             probs_list.append(probs)\n",
    "#             targets_list.append(yb.numpy().squeeze())\n",
    "#\n",
    "#     all_probs = np.concatenate(probs_list)\n",
    "#     all_targets = np.concatenate(targets_list)\n",
    "#     all_preds = (all_probs > 0.5).astype(int)   # you can tune threshold later\n",
    "#\n",
    "#     # compute metrics\n",
    "#     accuracy = (all_preds == all_targets).mean()\n",
    "#     precision = precision_score(all_targets, all_preds, zero_division=0)\n",
    "#     recall = recall_score(all_targets, all_preds, zero_division=0)\n",
    "#     f1 = f1_score(all_targets, all_preds, zero_division=0)\n",
    "#     cm = confusion_matrix(all_targets, all_preds)\n",
    "#\n",
    "#     print(f\"Epoch {epoch+1}/{epochs} — train_loss: {train_epoch_loss:.4f}  val_f1: {f1:.4f}\")\n",
    "#     print(f\"Acc: {accuracy:.4f}, Prec: {precision:.4f}, Rec: {recall:.4f}\")\n",
    "#     print(\"Confusion matrix:\\n\", cm)\n",
    "#\n",
    "#     wandb.log({\n",
    "#         \"val_accuracy\": accuracy,\n",
    "#         \"val_precision\": precision,\n",
    "#         \"val_recall\": recall,\n",
    "#         \"val_f1\": f1\n",
    "#     })\n",
    "#\n",
    "#     # -------- early stopping logic --------\n",
    "#\n",
    "#     if monitor == \"f1\":\n",
    "#         current = f1\n",
    "#     elif monitor == \"precision\":\n",
    "#         current = precision\n",
    "#     elif monitor == \"recall\":\n",
    "#         current = recall\n",
    "#     elif monitor == \"accuracy\":\n",
    "#         current = accuracy\n",
    "#     else:\n",
    "#         raise ValueError(\"Unknown monitor metric\")\n",
    "#\n",
    "#     improved = (current > best_metric) if mode == \"max\" else (current < best_metric)\n",
    "#     if improved:\n",
    "#         best_metric = current\n",
    "#         wait = 0\n",
    "#         torch.save(model.state_dict(), best_model_path)   # save best weights\n",
    "#         print(f\"  New best {monitor}: {best_metric:.4f}. Saved model.\")\n",
    "#     else:\n",
    "#         wait += 1\n",
    "#         print(f\"  No improvement for {wait} epoch(s).\")\n",
    "#\n",
    "#     if wait >= patience:\n",
    "#         print(\"Early stopping triggered. Restoring best model.\")\n",
    "#         break\n",
    "#\n",
    "#\n",
    "# model.load_state_dict(torch.load(best_model_path))\n",
    "#\n",
    "# model.load_state_dict(torch.load(best_model_path))\n",
    "# model.eval()\n",
    "#\n",
    "# all_preds = []\n",
    "# all_targets = []\n",
    "#\n",
    "# with torch.no_grad():\n",
    "#     for xb, yb in val_loader:\n",
    "#         logits = model(xb)\n",
    "#         probs = torch.sigmoid(logits)\n",
    "#         preds = (probs > 0.5).long()\n",
    "#         all_preds.append(preds.cpu())\n",
    "#         all_targets.append(yb.unsqueeze(1).cpu())\n",
    "#\n",
    "# # Convert to numpy arrays\n",
    "# all_preds = torch.cat(all_preds).squeeze().numpy()\n",
    "# all_targets = torch.cat(all_targets).squeeze().numpy()\n",
    "#\n",
    "# # --- Compute metrics ---\n",
    "# accuracy = accuracy_score(all_targets, all_preds)\n",
    "# precision = precision_score(all_targets, all_preds, zero_division=0)\n",
    "# recall = recall_score(all_targets, all_preds, zero_division=0)\n",
    "# f1 = f1_score(all_targets, all_preds, zero_division=0)\n",
    "# cm = confusion_matrix(all_targets, all_preds)\n",
    "#\n",
    "# # --- Print results ---\n",
    "# print(\"Best Model Validation Metrics:\")\n",
    "# print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "# print(f\"Precision: {precision:.4f}\")\n",
    "# print(f\"Recall:    {recall:.4f}\")\n",
    "# print(f\"F1-score:  {f1:.4f}\")\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(cm)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # --- Example hyperparameter grid\n",
    "# param_grid = {\n",
    "#     \"lr\": [1e-3, 5e-4, 0.1],\n",
    "#     \"hidden_dim\": [16, 32, 64],\n",
    "#     \"dropout_p\": [0.0, 0.2],\n",
    "#     \"epochs\": [10, 20]\n",
    "# }\n",
    "#\n",
    "# # --- Create all possible combinations\n",
    "# param_combinations = list(itertools.product(*param_grid.values()))\n",
    "#\n",
    "# # --- Iterate through all combinations\n",
    "# for combo in param_combinations:\n",
    "#     params = dict(zip(param_grid.keys(), combo))\n",
    "#     print(f\"\\nRunning grid search with params: {params}\")\n",
    "#\n",
    "#     wandb.init(project=\"grid_search_magicalnet\", config=params)\n",
    "#     config = wandb.config\n",
    "#\n",
    "#     # Initialize model, loss, optimizer\n",
    "#     model = MagicalNet(in_dim=9, hidden_dim=config.hidden_dim, dropout_p=config.dropout_p)\n",
    "#     criterion = nn.BCEWithLogitsLoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
    "#\n",
    "#     # --- Training loop (your original)\n",
    "#     for epoch in range(config.epochs):\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#\n",
    "#         for xb, yb in train_loader:\n",
    "#             xb, yb = xb, yb.unsqueeze(1)\n",
    "#             optimizer.zero_grad()\n",
    "#             logits = model(xb)\n",
    "#             loss = criterion(logits, yb)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             running_loss += loss.item() * xb.size(0)\n",
    "#\n",
    "#         epoch_loss = running_loss / len(train_loader.dataset)\n",
    "#         wandb.log({\"train_loss\": epoch_loss, \"epoch\": epoch + 1})\n",
    "#         print(f\"Epoch {epoch+1}/{config.epochs} — loss: {epoch_loss:.4f}\")\n",
    "#\n",
    "#     # --- Validation accuracy check\n",
    "#     model.eval()\n",
    "#     correct, total = 0, 0\n",
    "#     with torch.no_grad():\n",
    "#         for xb, yb in val_loader:\n",
    "#             logits = model(xb)\n",
    "#             preds = (torch.sigmoid(logits) > 0.5).long()\n",
    "#             correct += (preds.squeeze() == yb).sum().item()\n",
    "#             total += yb.size(0)\n",
    "#     acc = correct / total\n",
    "#     wandb.log({\"val_accuracy\": acc})\n",
    "#     print(f\"Validation accuracy: {acc:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- Hyperparameter grid\n",
    "param_grid = {\n",
    "    \"lr\": [1e-3, 5e-4],\n",
    "    \"hidden_dim\": [32, 64],\n",
    "    \"dropout_p\": [0.0, 0.2],\n",
    "    \"epochs\": [10]\n",
    "}\n",
    "param_combinations = list(itertools.product(*param_grid.values()))\n",
    "\n",
    "# --- Early stopping settings (you can tune these)\n",
    "monitor = \"f1\"\n",
    "mode = \"max\"\n",
    "patience = 100\n",
    "\n",
    "# --- Grid search\n",
    "for combo in param_combinations:\n",
    "    params = dict(zip(param_grid.keys(), combo))\n",
    "    print(f\"\\nRunning grid search with params: {params}\")\n",
    "\n",
    "    run = wandb.init(project=\"grid_search_magicalnet\", config=params, reinit=True)\n",
    "    config = wandb.config\n",
    "\n",
    "    # unique path for best model for this run\n",
    "    best_model_path = f\"best_1.pt\"\n",
    "\n",
    "    # build model / criterion / optimizer\n",
    "    model = MagicalNet(in_dim=9, hidden_dim=config.hidden_dim, dropout_p=config.dropout_p)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
    "\n",
    "    # early stopping state\n",
    "    best_metric = -float(\"inf\") if mode == \"max\" else float(\"inf\")\n",
    "    wait = 0\n",
    "    best_epoch = -1\n",
    "    best_metrics = None\n",
    "\n",
    "    # training + validation per epoch (so we can early-stop)\n",
    "    for epoch in range(config.epochs):\n",
    "        # -------- training --------\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb, yb.unsqueeze(1)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * xb.size(0)\n",
    "\n",
    "        train_epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        # -------- validation --------\n",
    "        model.eval()\n",
    "        probs_list = []\n",
    "        targets_list = []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                logits = model(xb)\n",
    "                probs = torch.sigmoid(logits).cpu().numpy().squeeze()\n",
    "                probs_list.append(probs)\n",
    "                targets_list.append(yb.numpy().squeeze())\n",
    "\n",
    "        all_probs = np.concatenate(probs_list)\n",
    "        all_targets = np.concatenate(targets_list).astype(int)\n",
    "        # default threshold 0.5; you can also sweep later\n",
    "        all_preds = (all_probs > 0.5).astype(int)\n",
    "\n",
    "        # compute metrics\n",
    "        prec = precision_score(all_targets, all_preds, zero_division=0)\n",
    "        rec = recall_score(all_targets, all_preds, zero_division=0)\n",
    "        f1 = f1_score(all_targets, all_preds, zero_division=0)\n",
    "        acc = accuracy_score(all_targets, all_preds)\n",
    "        cm = confusion_matrix(all_targets, all_preds)\n",
    "\n",
    "        # choose current metric for early stopping\n",
    "        if monitor == \"f1\":\n",
    "            current = f1\n",
    "        elif monitor == \"precision\":\n",
    "            current = prec\n",
    "        elif monitor == \"recall\":\n",
    "            current = rec\n",
    "        elif monitor == \"accuracy\":\n",
    "            current = acc\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown monitor metric: {monitor}\")\n",
    "\n",
    "        # logging\n",
    "        wandb.log({\n",
    "            \"train_loss\": train_epoch_loss,\n",
    "            \"val_accuracy\": acc,\n",
    "            \"val_precision\": prec,\n",
    "            \"val_recall\": rec,\n",
    "            \"val_f1\": f1,\n",
    "            \"epoch\": epoch + 1\n",
    "        })\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{config.epochs} — train_loss: {train_epoch_loss:.4f}  val_f1: {f1:.4f}\")\n",
    "\n",
    "        # early stopping decision\n",
    "        improved = (current > best_metric) if mode == \"max\" else (current < best_metric)\n",
    "        if improved:\n",
    "            best_metric = current\n",
    "            wait = 0\n",
    "            best_epoch = epoch + 1\n",
    "            best_metrics = {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"confusion_matrix\": cm}\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"  New best {monitor}: {best_metric:.4f} (saved)\")\n",
    "        else:\n",
    "            wait += 1\n",
    "            print(f\"  No improvement for {wait} epoch(s) (patience={patience})\")\n",
    "\n",
    "        if wait >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    # After training loop: load best model (if saved) and evaluate final metrics on validation set\n",
    "    if best_metrics is not None:\n",
    "        model.load_state_dict(torch.load(best_model_path, map_location=\"cpu\"))\n",
    "        model.eval()\n",
    "        # recompute metrics to be safe (same code as above)\n",
    "        probs_list = []\n",
    "        targets_list = []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                logits = model(xb)\n",
    "                probs = torch.sigmoid(logits).cpu().numpy().squeeze()\n",
    "                probs_list.append(probs)\n",
    "                targets_list.append(yb.numpy().squeeze())\n",
    "\n",
    "        all_probs = np.concatenate(probs_list)\n",
    "        all_targets = np.concatenate(targets_list).astype(int)\n",
    "        all_preds = (all_probs > 0.5).astype(int)\n",
    "\n",
    "        prec = precision_score(all_targets, all_preds, zero_division=0)\n",
    "        rec = recall_score(all_targets, all_preds, zero_division=0)\n",
    "        f1 = f1_score(all_targets, all_preds, zero_division=0)\n",
    "        acc = accuracy_score(all_targets, all_preds)\n",
    "        cm = confusion_matrix(all_targets, all_preds)\n",
    "\n",
    "        # log final best-run metrics\n",
    "        wandb.log({\n",
    "            \"best_val_accuracy\": acc,\n",
    "            \"best_val_precision\": prec,\n",
    "            \"best_val_recall\": rec,\n",
    "            \"best_val_f1\": f1\n",
    "        })\n",
    "        print(\"BEST validation metrics (loaded best model):\")\n",
    "        print(f\"Accuracy:  {acc:.4f}\")\n",
    "        print(f\"Precision: {prec:.4f}\")\n",
    "        print(f\"Recall:    {rec:.4f}\")\n",
    "        print(f\"F1-score:  {f1:.4f}\")\n",
    "        print(\"Confusion matrix:\\n\", cm)\n",
    "    else:\n",
    "        print(\"No improvement recorded during run; no best model saved.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "wandb.finish()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Recreate the same model architecture\n",
    "model = MagicalNet(in_dim=in_features, hidden_dim=64)\n",
    "\n",
    "# Load the saved weights\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "# Example input — your real data goes here\n",
    "new_input = [[20.2, 5.6, 1.8, 0.12, 0.01, 1.3, 30.5, 59.7, 180.0]]\n",
    "\n",
    "# Convert to tensor\n",
    "x = torch.tensor(new_input, dtype=torch.float32)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    logit = model(x)\n",
    "    prob = torch.sigmoid(logit).item()      # convert to probability\n",
    "    pred = int(prob > 0.5)\n",
    "\n",
    "if pred == 1:\n",
    "    print(f\"Prediction: Class 1 (probability: {prob:.3f})\")\n",
    "else:\n",
    "    print(f\"Prediction: Class 0 (probability: {prob:.3f})\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "ef5db1a2a3a2440eb025491bbfab5f2d",
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": "4",
 "nbformat_minor": "0",
 "version": "0"
}
